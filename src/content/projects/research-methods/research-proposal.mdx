---
title: "Bridging the Gap: The Role of LLMs in Junior Developer Growth and Senior-Led Knowledge Workflows"
description: "Research Proposal"
module: "research-methods"
project: "unit9"
date: "2025-01-01"
unit: 11
---

*This is the presentation transcript that was delivered as a research proposal*

## Introduction
Hello, my name is Nil Distefano, and in this presentation I will introduce my research
proposal titled "Bridging the Gap: The Role of LLMs in Junior Developer Growth and
Senior-Led Knowledge Workflows."
This proposal explores how the increasing use of large language models, or LLMs, is
shaping the dynamics between junior and senior developers, particularly in teams
where seniors contribute not only technical guidance but also critical business or
domain-specific knowledge.
## Context and Research Problem
In many modern software teams, senior developers often hold critical domain or
business knowledge, which plays a key role in project success. Meanwhile, junior
developers typically acquire this understanding over time through collaboration,
exposure, and mentoring.
With the introduction of LLM-based assistants like GitHub Copilot and ChatGPT, both
junior and senior developers now have powerful tools to write, review, and
understand code faster.
However, this raises a crucial question: Are these tools enhancing or disrupting the
natural process of learning and collaboration between experience levels?Specifically, does relying on LLMs reduce opportunities for mentorship and business
knowledge sharing, or does it accelerate junior growth by filling knowledge gaps
more quickly?
## Research Question
The research question guiding this proposal is: “How do large language models
influence the collaboration dynamics and long-term knowledge development of junior
developers in teams led by senior domain experts?”.
This question allows for an investigation into both short-term and long-term effects
of LLMs on developer growth, team efficiency, and evolving workflows.
It also invites exploration of how knowledge is transferred, and whether LLMs are
serving as a support system or potentially a shortcut that bypasses deeper learning.
## Aim and Objectives
The aim of this research is to explore the impact of LLMs on how junior developers
learn, grow, and contribute within software teams led by senior members with strong
business knowledge.
To achieve this aim, the project will focus on four main objectives:
1. To assess how LLMs are used differently by juniors and seniors in daily
development work.
2. To evaluate whether LLMs help or hinder the acquisition of domain-specific
knowledge by junior developers.
3. To examine how LLMs are influencing team collaboration, including task
delegation and communication patterns.
4. To identify long-term implications for onboarding, skill development, and
hiring practices in AI-assisted development teams.
## Literature Review
The literature supporting this research, covers mainly three topics:
1. LLM Capabilities in Software Development
2. Human-AI Collaboration and Developer Roles
3. Security and Knowledge Transfer Concerns
## Literature Review — LLM Capabilities
Large language models have emerged as powerful tools in software development.
Architecturally, they rely on transformers and attention mechanisms introduced by
Vaswani et al. in 2017, allowing them to understand both natural and programming
languages effectively.
As Chen et al. (2021) note, LLMs like Codex and ChatGPT are trained on large
datasets and perform a wide range of tasks including code generation, debugging,
summarization, and documentation.
Tools like CodeBERT and CodeT5 extend these capabilities further (Negri-Ribalta et
al., 2024). According to Tabarsi et al. (2025), these assistants significantly boost
productivity, especially by automating repetitive coding tasks and assisting with
syntax or framework-specific queries.
These capabilities form the technical foundation that now reshapes daily
development workflows.
## Literature Review — Collaboration & Roles
The way developers collaborate with LLMs differs significantly by experience level.
Nettur et al. (2025) show that senior developers use LLMs strategically to offload
repetitive tasks such as refactoring or test writing, allowing them to focus on
high-level decisions. In contrast, juniors rely on these tools to understand syntax and
logic, effectively treating them as learning aids.
However, as Chatterjee et al. (2024) highlight, this creates a risk of over-reliance.
Stray et al. (2025) add that without sufficient oversight or understanding, juniors may
adopt flawed, or suboptimal solutions suggested by the AI.Across both groups, the role of prompt engineering — the skill of asking the right
questions — has become essential to extracting useful, safe, and context-aware
output.
## Literature Review — Risks and Knowledge Transfer
It is clear that while LLMs are powerful, they also introduce significant risks,
particularly for less experienced users.
Negri-Ribalta et al. (2024) found that around 40 to 44% of Copilot-generated code
samples contained security vulnerabilities, such as hardcoded credentials and weak
input validation.
These issues are made worse by LLM non-determinism, meaning the same prompt
can yield multiple different outputs (Tabarsi et al., 2025).
Most critically for this proposal, domain-specific business logic, which senior
developers often carry, is not explicitly learned or encoded by LLMs. Stray et al.
(2025) note that juniors may skip over acquiring this contextual knowledge if they
overly rely on LLMs.
This creates a subtle but serious risk: faster code, but a shallower understanding of
why it matters.
## Methodology
This research proposes a comparative task-based study focused on development
that requires some form of business knowledge. A sum of coding tasks, which
implicitly depends on domain-specific context, will be completed separately by a
junior and a senior developer. Both will be allowed to use an LLM such as ChatGPT
or Copilot.The data collected will include the generated code, the prompts used, and a brief
follow-up interview with each participant.
Of particular interest is whether the junior accepts the LLM output without noticing
missing context, whether they ask for help, or if they rely solely on the tool. In
contrast, we would observe whether the senior recognizes and corrects these flaws,
uses better prompts, or verifies outputs against their domain understanding.
This setup allows a structured comparison of how experience and business
knowledge shape human-AI collaboration.
## Timeline
This research would be carried out over a ten-week period.
- Weeks 1 and 2: Refine the literature review and finalise the research design.
- Weeks 3 and 4: Create the coding task, define the interview questions, and set
up the LLM environment.
- Weeks 5 and 6: Data collection, where both junior and senior participants
complete the task and take part in post-task interviews.
- Weeks 7 and 8: Data analysis, comparing code quality, prompt usage, and
reasoning patterns.
- Weeks 9 and 10: Write-up and final review for submission.

This timeline is designed to balance thorough analysis with the scope and
constraints of a small-scale academic proposal.
## Expected Contribution
This research aims to contribute meaningful insights into how LLM-based tools are
reshaping collaboration between junior and senior developers.

First, it will help clarify how LLM usage differs based on experience — particularly
how juniors and seniors approach the same task using the same tool.

Second, it will deepen our understanding of the role of domain knowledge in prompt
engineering and output validation, which is not well captured in most technical
studies.

Third, the study will identify risks such as over-reliance on LLMs, shallow
comprehension of business rules, and missed mentorship opportunities.

Finally, the research may support the development of best practices for onboarding
juniors and supporting developer growth in AI-assisted environments.

As LLMs become integrated into everyday development, they are changing how
teams are structured and how knowledge is transferred between experience levels.
This research matters because junior developers may increasingly learn how to
code, but not always why, especially in the context of business logic or internal
systems. The findings could help companies shape onboarding strategies,
mentorship practices, and ethical integration of LLMs into developer workflows.

## References
Chatterjee, S., Liu, C.L., Rowland, G. and Hogarth, T. (2024) The impact of AI tool on
engineering at ANZ Bank: An empirical study on GitHub Copilot within corporate
environment. arXiv preprint arXiv:2402.05636.

Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H.P., Kaplan, J. et al. (2021)
Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.
Available at: https://doi.org/10.48550/arXiv.2107.03374.

Negri-Ribalta, C., Geraud-Stewart, R., Sergeeva, A. and Lenzini, G. (2024) ‘A
systematic literature review on the impact of AI models on the security of code
generation’, Frontiers in Big Data, 7, p.1386720. Available at:
https://doi.org/10.3389/fdata.2024.1386720.

Nettur, S.B., Karpurapu, S., Nettur, U., Gajja, L.S., Myneni, S. and Dusi, A. (2025) The
role of GitHub Copilot on software development: A perspective on productivity, security,
best practices and future directions. arXiv preprint arXiv:2502.13199.

Noy, S. and Zhang, W. (2023) ‘Experimental evidence on the productivity effects of
generative artificial intelligence’, Science, 381(6608), pp.851–857. Available at:
https://doi.org/10.1126/science.adh2586.

Rasnayaka, S., Wang, G., Shariffdeen, R. and Iyer, G.N. (2024) ‘An empirical study on
usage and perceptions of LLMs in a software engineering project’, Proceedings of the
1st International Workshop on Large Language Models for Code. Lisbon, April 2024,
pp.111–118.

Stray, V., Moe, N.B., Ganeshan, N. and Kobbenes, S. (2025) ‘Generative AI and
developer workflows: How GitHub Copilot and ChatGPT influence solo and pair
programming’, Proceedings of the 58th Hawaii International Conference on System

Sciences.Tabarsi, B., Reichert, H., Limke, A., Kuttal, S. and Barnes, T. (2025) LLMs' reshaping of
people, processes, products, and society in software development: A comprehensive
exploration with early adopters. arXiv preprint arXiv:2503.05012.

Tadi, S.R.C.C.T. (2025) ‘Developer and LLM pair programming: An empirical study of
role dynamics and prompt-based collaboration’, International Journal of Advanced

Research in Science, Communication and Technology, 5(3), p.436. Available at:
https://doi.org/10.48175/IJARSCT-26358.

Tang, N., Chen, M., Ning, Z., Bansal, A., Huang, Y., McMillan, C. and Li, T. (2023) ‘An
empirical study of developer behaviors for validating and repairing AI-generated
code’, 13th Workshop on the Intersection of HCI and PL. Boston, January 2023.

Treude, C. and Gerosa, M.A. (2025) How developers interact with AI: A taxonomy of
human-AI collaboration in software engineering. arXiv preprint arXiv:2501.08774.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N. et al. (2017)
‘Attention is all you need’, Advances in Neural Information Processing Systems, 30,
pp.5998–6008.

Yetistiren, B., Özsoy, I., Ayerdem, M. and Tüzün, E. (2023) Evaluating the code quality
of AI-assisted code generation tools: An empirical study on GitHub Copilot, Amazon
CodeWhisperer, and ChatGPT. arXiv preprint arXiv:2304.10778.

## Note on Transcript Preparation
This transcript was prepared based on the live recording of the presentation using
Loom. The auto-generated transcript was cleaned and formatted to improve clarity
and structure. 