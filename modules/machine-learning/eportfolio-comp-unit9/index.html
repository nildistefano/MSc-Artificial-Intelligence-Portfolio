<!DOCTYPE html><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"><script type="module">const e=document.getElementById("link-menu-button"),n=document.getElementById("link-menu"),i=document.getElementById("open-indicator");e.addEventListener("click",()=>{n.classList.contains("opacity-0")?(n.classList.remove("pointer-events-none"),n.classList.remove("opacity-0"),i.innerText="-"):(n.classList.add("pointer-events-none"),n.classList.add("opacity-0"),i.innerText="+")});document.addEventListener("click",t=>{const s=t.target===e||e.contains(t.target),c=t.target===n||n.contains(t.target);!s&&!c&&(n.classList.add("pointer-events-none"),n.classList.add("opacity-0"),i.innerText="+")});</script> <html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.0.0"><title>Machine Learning</title><meta name="description" content="This Machine Learning module provides a practical, hands-on introduction to machine learning concepts, algorithms, and frameworks, emphasizing real-world data analytics, systematic implementation, and the ethical, professional, and collaborative aspects of deploying machine learning solutions."><meta property="og:title" content="Machine Learning"><meta property="og:description" content="This Machine Learning module provides a practical, hands-on introduction to machine learning concepts, algorithms, and frameworks, emphasizing real-world data analytics, systematic implementation, and the ethical, professional, and collaborative aspects of deploying machine learning solutions."><meta property="og:image" content><link rel="stylesheet" href="/MSc-Artificial-Intelligence-Portfolio/_astro/about.msOe3G2r.css">
<style>@import"https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap";html{font-family:Inter,sans-serif;background:#000}*{margin:0;padding:0;box-sizing:border-box;-webkit-font-smoothing:antialiased;color:#fff}code{font-family:Menlo,Monaco,Lucida Console,Liberation Mono,DejaVu Sans Mono,Bitstream Vera Sans Mono,Courier New,monospace}.hover-underline{-webkit-text-decoration:underline 1px rgba(0,0,0,0);text-decoration:underline 1px rgba(0,0,0,0);text-underline-offset:5px;transition:text-decoration-color .3s}.post:hover .hover-underline{text-decoration-color:#fff}
[data-astro-image]{width:100%;height:auto;-o-object-fit:var(--fit);object-fit:var(--fit);-o-object-position:var(--pos);object-position:var(--pos);aspect-ratio:var(--w) / var(--h)}[data-astro-image=responsive]{max-width:calc(var(--w) * 1px);max-height:calc(var(--h) * 1px)}[data-astro-image=fixed]{width:calc(var(--w) * 1px);height:calc(var(--h) * 1px)}
</style></head> <body> <header> <div class="px-6 py-6 max-w-2xl mx-auto flex items-center justify-between"> <a href="/MSc-Artificial-Intelligence-Portfolio/" class="justify-content: center"> <img src="/MSc-Artificial-Intelligence-Portfolio/logo.jpeg" alt="logo" class="rounded-full" width="50" height="50" loading="lazy" decoding="async" class="rounded-full"> </a> <nav class="ml-auto mr-6 sm:m-0 flex justify-content: center"> <ul class="hidden sm:flex sm:items-center sm:gap-2"> <li> <a class="group px-4 py-2 rounded-lg hover:bg-gray-bg opacity-60 hover:opacity-100 transition-all" href="/MSc-Artificial-Intelligence-Portfolio/" target="_self"> Home </a> </li><li> <a class="group px-4 py-2 rounded-lg hover:bg-gray-bg opacity-60 hover:opacity-100 transition-all" href="/MSc-Artificial-Intelligence-Portfolio/about" target="_self"> About </a> </li><li> <a class="group px-4 py-2 rounded-lg hover:bg-gray-bg opacity-60 hover:opacity-100 transition-all" href="/MSc-Artificial-Intelligence-Portfolio/modules" target="_self"> Master&#39;s Modules </a> </li> </ul> <div class="relative sm:hidden"> <button id="link-menu-button" class="relative font-medium opacity-60 p-4">Menu <span id="open-indicator">+</span></button> <div id="link-menu" class="absolute p-2 right-0 bg-gray-bg rounded-lg w-44 transition-opacity ease-in-out duration-300 opacity-0 z-40"> <ul> <li> <a class="block pl-4 py-3" href="/MSc-Artificial-Intelligence-Portfolio/" target="_self"> Home </a> </li><li> <a class="block pl-4 py-3" href="/MSc-Artificial-Intelligence-Portfolio/about" target="_self"> About </a> </li><li> <a class="block pl-4 py-3" href="/MSc-Artificial-Intelligence-Portfolio/modules" target="_self"> Master&#39;s Modules </a> </li> </ul> </div> </div> </nav> <div> <a href="mailto:disnil7@gmail.com" class="block p-2 opacity-60 hover:opacity-100 transition-opacity" aria-label="Email"> <svg width="20" height="20" data-icon="mdi:email">   <symbol id="ai:mdi:email" viewBox="0 0 24 24"><path fill="currentColor" d="m20 8l-8 5l-8-5V6l8 5l8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2"/></symbol><use href="#ai:mdi:email"></use>  </svg> </a> </div> </div> </header> <main class="mb-32 max-w-4xl mx-auto px-8"> <section class="mt-10 mx-auto px-6"><h1 class="font-bold text-3xl mb-1">CNN Model Activity</h1><p class="text-sm font-semibold text-xl mt-4 text-gray-400">Unit 9</p><div class="mt-6 prose prose-invert"><p>The following project was provided as part of Unit 9 and focuses on object recognition tasks using Convolutional Neural Networks (CNNs). The primary objective was to implement the code, analyze the results, and reflect on its components.
The methods demonstrated here will be foundational for tasks in later units. You can refer to Unit 11 <a href="http://localhost:4321/MSc-Artificial-Intelligence-Portfolio/modules/machine-learning/final-project">here</a> for the personalized inplementation of this code for the final project.</p>
<p>Find below relevant snippets of the codes and my reasoning and understanding of each of the components.</p>
<hr/>
<h2 id="data-exploration">Data Exploration</h2>
<h3 id="viewing-the-dataset">Viewing the Dataset</h3>
<p>Exploring the dataset visually was essential for understanding its structure. Each image is 32×32×3, where the dimensions represent width, height, and RGB color channels. This was probably the most complex data dimension we have worked with so far.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="python"><code><span class="line"><span style="color:#6A737D"># Displaying the first image using IPython display</span></span>
<span class="line"><span style="color:#E1E4E8">pic </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> array_to_img(x_train_all[</span><span style="color:#79B8FF">0</span><span style="color:#E1E4E8">])</span></span>
<span class="line"><span style="color:#E1E4E8">display(pic)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Displaying the first image using Matplotlib</span></span>
<span class="line"><span style="color:#E1E4E8">plt.imshow(x_train_all[</span><span style="color:#79B8FF">0</span><span style="color:#E1E4E8">])</span></span></code></pre>
<p><img src="/MSc-Artificial-Intelligence-Portfolio/projects/unit9/unit-9.1.1-output.png" alt="Output"/></p>
<hr/>
<h2 id="data-preprocessing">Data Preprocessing</h2>
<p>In order for the model to learn from the data provided, we need to ensure that the information is not only in the correct format but also transformed or simplified to allow the model to use it optimally.</p>
<h3 id="scaling-the-input-data">Scaling the Input Data</h3>
<p>Scaling pixel values to the range [0, 1] ensures numerical stability during training and helps the model converge faster. Raw pixel values range from 0 to 255, so dividing by 255 standardizes them into a more manageable magnitude.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="python"><code><span class="line"><span style="color:#E1E4E8">x_train_all </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> x_train_all </span><span style="color:#F97583">/</span><span style="color:#79B8FF"> 255.0</span></span>
<span class="line"><span style="color:#E1E4E8">x_test </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> x_test </span><span style="color:#F97583">/</span><span style="color:#79B8FF"> 255.0</span></span></code></pre>
<h3 id="categorical-encoding-of-labels">Categorical Encoding of Labels</h3>
<p>Since we have 10 classes, converting the labels to categorical format enables the model to compute probabilities for each class during classification. Note the difference between having the output as a magnitude ranging from 0 to 10, versus having 10 labels named 1-10.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="python"><code><span class="line"><span style="color:#E1E4E8">y_cat_train_all </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> to_categorical(y_train_all, </span><span style="color:#79B8FF">10</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#E1E4E8">y_cat_test </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> to_categorical(y_test, </span><span style="color:#79B8FF">10</span><span style="color:#E1E4E8">)</span></span></code></pre>
<h3 id="creating-validation-dataset">Creating Validation Dataset</h3>
<p>Splitting the training data into training and validation subsets ensures that the model can be evaluated on unseen data during training. This approach helps detect overfitting early. We will dive into this concept again during Unit 11.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="python"><code><span class="line"><span style="color:#79B8FF">VALIDATION_SIZE</span><span style="color:#F97583"> =</span><span style="color:#79B8FF"> 10000</span></span>
<span class="line"><span style="color:#E1E4E8">x_val </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> x_train_all[:</span><span style="color:#79B8FF">VALIDATION_SIZE</span><span style="color:#E1E4E8">]</span></span>
<span class="line"><span style="color:#E1E4E8">y_val_cat </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> y_cat_train_all[:</span><span style="color:#79B8FF">VALIDATION_SIZE</span><span style="color:#E1E4E8">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">x_train </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> x_train_all[</span><span style="color:#79B8FF">VALIDATION_SIZE</span><span style="color:#E1E4E8">:]</span></span>
<span class="line"><span style="color:#E1E4E8">y_cat_train </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> y_cat_train_all[</span><span style="color:#79B8FF">VALIDATION_SIZE</span><span style="color:#E1E4E8">:]</span></span></code></pre>
<hr/>
<h2 id="model-building">Model Building</h2>
<h3 id="creating-the-cnn-model">Creating the CNN Model</h3>
<p>The proposed architecture consists of two convolutional layers, each followed by max-pooling, to capture spatial hierarchies. A dense layer with 256 neurons is added for representation learning, followed by a softmax layer for multi-class classification.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="python"><code><span class="line"><span style="color:#E1E4E8">model </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> Sequential()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># First Convolutional Layer</span></span>
<span class="line"><span style="color:#E1E4E8">model.add(Conv2D(</span><span style="color:#FFAB70">filters</span><span style="color:#F97583">=</span><span style="color:#79B8FF">32</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">kernel_size</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">4</span><span style="color:#E1E4E8">,</span><span style="color:#79B8FF">4</span><span style="color:#E1E4E8">), </span><span style="color:#FFAB70">input_shape</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">32</span><span style="color:#E1E4E8">, </span><span style="color:#79B8FF">32</span><span style="color:#E1E4E8">, </span><span style="color:#79B8FF">3</span><span style="color:#E1E4E8">), </span><span style="color:#FFAB70">activation</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">&#39;relu&#39;</span><span style="color:#E1E4E8">))</span></span>
<span class="line"><span style="color:#E1E4E8">model.add(MaxPool2D(</span><span style="color:#FFAB70">pool_size</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">2</span><span style="color:#E1E4E8">, </span><span style="color:#79B8FF">2</span><span style="color:#E1E4E8">)))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Second Convolutional Layer</span></span>
<span class="line"><span style="color:#E1E4E8">model.add(Conv2D(</span><span style="color:#FFAB70">filters</span><span style="color:#F97583">=</span><span style="color:#79B8FF">32</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">kernel_size</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">4</span><span style="color:#E1E4E8">,</span><span style="color:#79B8FF">4</span><span style="color:#E1E4E8">), </span><span style="color:#FFAB70">activation</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">&#39;relu&#39;</span><span style="color:#E1E4E8">))</span></span>
<span class="line"><span style="color:#E1E4E8">model.add(MaxPool2D(</span><span style="color:#FFAB70">pool_size</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">2</span><span style="color:#E1E4E8">, </span><span style="color:#79B8FF">2</span><span style="color:#E1E4E8">)))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Flattening and Dense Layers</span></span>
<span class="line"><span style="color:#E1E4E8">model.add(Flatten())</span></span>
<span class="line"><span style="color:#E1E4E8">model.add(Dense(</span><span style="color:#79B8FF">256</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">activation</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">&#39;relu&#39;</span><span style="color:#E1E4E8">))</span></span>
<span class="line"><span style="color:#E1E4E8">model.add(Dense(</span><span style="color:#79B8FF">10</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">activation</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">&#39;softmax&#39;</span><span style="color:#E1E4E8">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Compiling the Model</span></span>
<span class="line"><span style="color:#E1E4E8">model.compile(</span><span style="color:#FFAB70">loss</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">&#39;categorical_crossentropy&#39;</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">optimizer</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">&#39;adam&#39;</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">metrics</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[</span><span style="color:#9ECBFF">&#39;accuracy&#39;</span><span style="color:#E1E4E8">])</span></span></code></pre>
<p>For this particular activity I left the model as is, and really focused on the dimensionallity change across layers, as seen below.</p>
<h3 id="model-summary">Model Summary</h3>













































<table><thead><tr><th><strong>Layer (type)</strong></th><th><strong>Output Shape</strong></th><th><strong>Param #</strong></th></tr></thead><tbody><tr><td>conv2d (Conv2D)</td><td>(None, 29, 29, 32)</td><td>1,568</td></tr><tr><td>max_pooling2d (MaxPooling2D)</td><td>(None, 14, 14, 32)</td><td>0</td></tr><tr><td>conv2d_1 (Conv2D)</td><td>(None, 11, 11, 32)</td><td>16,416</td></tr><tr><td>max_pooling2d_1 (MaxPooling2D)</td><td>(None, 5, 5, 32)</td><td>0</td></tr><tr><td>flatten (Flatten)</td><td>(None, 800)</td><td>0</td></tr><tr><td>dense (Dense)</td><td>(None, 256)</td><td>205,056</td></tr><tr><td>dense_1 (Dense)</td><td>(None, 10)</td><td>2,570</td></tr></tbody></table>
<p>As we can see, each of the convolutional layers are reducing the dimensionallity, as we are no forcing them to keep the original size. Equally is done by the max-pooling layers which simplify the output of the convolutional layers to provide a high level overview of the learned features. The dense layers converge all the information into a one-dimensional vector which is eventually reduced to size 10, with a probability for each of the classes.</p>
<hr/>
<h2 id="training-the-model">Training the Model</h2>
<h3 id="early-stopping">Early Stopping</h3>
<p>During training, I would like to highlight the Early Stopping mechanism. It monitors the validation loss during training and stops the process if no improvement is observed for a specified number of epochs. This prevents overfitting and saves computational resources. In this particular case, if the validation loss did not improve for two consecutive epochs, the trainign is stoped.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">from</span><span style="color:#E1E4E8"> tensorflow.keras.callbacks </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> EarlyStopping</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Setting up Early Stopping</span></span>
<span class="line"><span style="color:#E1E4E8">early_stop </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> EarlyStopping(</span><span style="color:#FFAB70">monitor</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">&#39;val_loss&#39;</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">patience</span><span style="color:#F97583">=</span><span style="color:#79B8FF">2</span><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Training the Model</span></span>
<span class="line"><span style="color:#E1E4E8">history </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> model.fit(x_train, y_cat_train, </span><span style="color:#FFAB70">epochs</span><span style="color:#F97583">=</span><span style="color:#79B8FF">25</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">validation_data</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">(x_val, y_val_cat), </span><span style="color:#FFAB70">callbacks</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[early_stop])</span></span></code></pre>
<h3 id="training-and-validation-metrics">Training and Validation Metrics</h3>
<p>The main take away from training was to really visualize how to losses decreased for both the datasets and when the model decided to stop. In the following plot we can see the results for higher patience values. Where the validation loss did not improve and the model began overfitting.</p>
<p><img src="/MSc-Artificial-Intelligence-Portfolio/projects/unit9/unit-9.2-output.png" alt="Output"/></p>
<hr/>
<h2 id="model-evaluation">Model Evaluation</h2>
<p>Evaluating on the test set provides a realistic measure of how the model performs on unseen data.</p>
<h3 id="classification-report-and-confusion-matrix">Classification Report and Confusion Matrix</h3>
<p>The classification report includes precision, recall, and F1-score, providing a detailed view of the model’s performance for each class.</p>







































































































<table><thead><tr><th>Class</th><th>Precision</th><th>Recall</th><th>F1-score</th><th>Support</th></tr></thead><tbody><tr><td>0</td><td>0.79</td><td>0.77</td><td>0.78</td><td>1000</td></tr><tr><td>1</td><td>0.84</td><td>0.89</td><td>0.87</td><td>1000</td></tr><tr><td>2</td><td>0.72</td><td>0.66</td><td>0.69</td><td>1000</td></tr><tr><td>3</td><td>0.55</td><td>0.59</td><td>0.57</td><td>1000</td></tr><tr><td>4</td><td>0.75</td><td>0.70</td><td>0.73</td><td>1000</td></tr><tr><td>5</td><td>0.64</td><td>0.67</td><td>0.66</td><td>1000</td></tr><tr><td>6</td><td>0.82</td><td>0.84</td><td>0.83</td><td>1000</td></tr><tr><td>7</td><td>0.86</td><td>0.80</td><td>0.83</td><td>1000</td></tr><tr><td>8</td><td>0.81</td><td>0.89</td><td>0.85</td><td>1000</td></tr><tr><td>9</td><td>0.83</td><td>0.81</td><td>0.82</td><td>1000</td></tr><tr><td><strong>Accuracy</strong></td><td></td><td></td><td>0.76</td><td>10000</td></tr><tr><td><strong>Macro avg</strong></td><td>0.76</td><td>0.76</td><td>0.76</td><td>10000</td></tr><tr><td><strong>Weighted avg</strong></td><td>0.76</td><td>0.76</td><td>0.76</td><td>10000</td></tr></tbody></table>
<p>The confusion matrix visualizes correct and incorrect predictions.</p>




















































































































































<table><thead><tr><th></th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th></tr></thead><tbody><tr><td><strong>0</strong></td><td>765</td><td>21</td><td>44</td><td>18</td><td>17</td><td>5</td><td>3</td><td>9</td><td>87</td><td>31</td></tr><tr><td><strong>1</strong></td><td>13</td><td>889</td><td>1</td><td>6</td><td>2</td><td>2</td><td>4</td><td>1</td><td>26</td><td>56</td></tr><tr><td><strong>2</strong></td><td>59</td><td>6</td><td>656</td><td>71</td><td>60</td><td>55</td><td>46</td><td>18</td><td>19</td><td>10</td></tr><tr><td><strong>3</strong></td><td>14</td><td>16</td><td>49</td><td>591</td><td>57</td><td>165</td><td>53</td><td>23</td><td>17</td><td>15</td></tr><tr><td><strong>4</strong></td><td>22</td><td>5</td><td>53</td><td>76</td><td>704</td><td>41</td><td>49</td><td>36</td><td>11</td><td>3</td></tr><tr><td><strong>5</strong></td><td>10</td><td>2</td><td>41</td><td>176</td><td>39</td><td>668</td><td>16</td><td>25</td><td>8</td><td>15</td></tr><tr><td><strong>6</strong></td><td>6</td><td>2</td><td>28</td><td>71</td><td>18</td><td>23</td><td>836</td><td>2</td><td>9</td><td>5</td></tr><tr><td><strong>7</strong></td><td>12</td><td>2</td><td>26</td><td>36</td><td>40</td><td>64</td><td>8</td><td>796</td><td>4</td><td>12</td></tr><tr><td><strong>8</strong></td><td>38</td><td>27</td><td>10</td><td>4</td><td>1</td><td>6</td><td>3</td><td>0</td><td>888</td><td>23</td></tr><tr><td><strong>9</strong></td><td>32</td><td>84</td><td>6</td><td>18</td><td>4</td><td>7</td><td>1</td><td>11</td><td>29</td><td>808</td></tr></tbody></table>
<hr/>
<h2 id="predicting-on-single-image">Predicting on Single Image</h2>
<p>Visualizing individual predictions allows us to verify the model’s accuracy for specific examples. This step is especially interesting to visualize the results in a visual manner.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">from</span><span style="color:#E1E4E8"> random </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> randint</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">idx </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> randint(</span><span style="color:#79B8FF">0</span><span style="color:#E1E4E8">, </span><span style="color:#79B8FF">len</span><span style="color:#E1E4E8">(x_test)</span><span style="color:#F97583">-</span><span style="color:#79B8FF">1</span><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">test_image </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> x_test[idx]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">plt.imshow(test_image)</span></span>
<span class="line"><span style="color:#E1E4E8">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#79B8FF">print</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">f</span><span style="color:#9ECBFF">&quot;Real Label: </span><span style="color:#79B8FF">{CLASS_NAMES</span><span style="color:#E1E4E8">[y_test_multiclass[idx]]</span><span style="color:#79B8FF">}</span><span style="color:#9ECBFF">&quot;</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#79B8FF">print</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">f</span><span style="color:#9ECBFF">&quot;Predicted Label: </span><span style="color:#79B8FF">{CLASS_NAMES</span><span style="color:#E1E4E8">[predictions[idx]]</span><span style="color:#79B8FF">}</span><span style="color:#9ECBFF">&quot;</span><span style="color:#E1E4E8">)</span></span></code></pre>
<p><img src="/MSc-Artificial-Intelligence-Portfolio/projects/unit9/unit-9.1.1-output.png" alt="Output"/></p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="plaintext"><code><span class="line"><span>Real Label: Frog</span></span>
<span class="line"><span>Predicted Label: Frog</span></span></code></pre>
<hr/>
<p>Overall this was an excelent activity to really grasp on the concepts of neural networks and visualize the results of a simple use case.</p></div></section> </main> <footer></footer> </body></html>